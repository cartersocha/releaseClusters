{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "filepath1 = r'/Users/cartersocha/Downloads/instgramHashtagCounts.xlsx'\n",
    "instaHashtagDf = pd.read_excel(filepath1)\n",
    "\n",
    "filepath2 = r'/Users/cartersocha/Downloads/tweetCountTest.xlsx'\n",
    "dailyTweetDf = pd.read_excel(filepath2)\n",
    "\n",
    "filepath3 = r'/Users/cartersocha/Desktop/ReleaseData.xlsx'\n",
    "releaseDf = pd.read_excel(filepath3, \"ShowInfoEndStart\")\n",
    "\n",
    "filepath4 = r'/Users/cartersocha/Downloads/instgramAccountCounts.xlsx'\n",
    "igAccountDf = pd.read_excel(filepath4)\n",
    "\n",
    "filepath5 = r'/Users/cartersocha/Downloads/redditCountTest.xlsx'\n",
    "redditSubsDf = pd.read_excel(filepath5)\n",
    "\n",
    "filepath6 = r'/Users/cartersocha/Downloads/redditCommentCombo.csv'\n",
    "redditCommentsDf = pd.read_csv(filepath6)\n",
    "\n",
    "filepath8 = r'/Users/cartersocha/Desktop/ReleaseData.xlsx'\n",
    "releaseDateDf = pd.read_excel(filepath8, \"ReleaseDateData\")\n",
    "\n",
    "filepath10 = r'/Users/cartersocha/Downloads/googleDataset2.csv'\n",
    "googleDailyData = pd.read_csv(filepath10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DateTimeConvert(dateDf, dateColumn):\n",
    "    dateDf[dateColumn] = pd.to_datetime(dateDf[dateColumn])  \n",
    "\n",
    "    return dateDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiffMaker(fillnaDf, valueColumn, dateColumn):\n",
    "    fillnaDf.sort_values(['TvShow', dateColumn], inplace=True)\n",
    "\n",
    "    fillnaDf['diffs'] = fillnaDf.groupby(['TvShow'])[valueColumn].transform(lambda x: x.diff()).fillna(0)\n",
    "\n",
    "    fillnaDf.sort_index(inplace=True)\n",
    "\n",
    "    return fillnaDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveData(release,showDf):\n",
    "\n",
    "    bigDf = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(release)):\n",
    "        show = release['TvShow'][i]\n",
    "        firstDate = release['Release Date'][i]\n",
    "        secondDate = release['90DayDate'][i]\n",
    "\n",
    "        smallDf = showDf[showDf['TvShow'] == show]\n",
    "\n",
    "        newdf = smallDf[smallDf['RunDate'].between(firstDate, secondDate)]\n",
    "\n",
    "        bigDf = bigDf.append(newdf,ignore_index=True)\n",
    "\n",
    "    return bigDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergeDfs(mainDf, secondDf, columnName):\n",
    "\n",
    "    merged = pd.merge(mainDf,secondDf, how='outer', on=columnName)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def NegativeDiffs(diffDf,columnName):\n",
    "\n",
    "    diffDf['zeroedDiffs'] = np.where((diffDf[columnName] < 0), 0, diffDf[columnName])\n",
    "\n",
    "    return diffDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SumSocialMedia(sumDf,columnName,trigger):\n",
    "    # check to see if this is episode count or generic summarization\n",
    "    if trigger == 1:\n",
    "        summarizedDf = sumDf.groupby(columnName, as_index=False).sum()\n",
    "        summarizedDf = pd.DataFrame(summarizedDf)\n",
    "    \n",
    "    else:\n",
    "        summarizedDf = sumDf.groupby(columnName, as_index=False).count()\n",
    "        summarizedDf = pd.DataFrame(summarizedDf)\n",
    "    \n",
    "    return summarizedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def NormalizeData(normalDf,columnName):\n",
    "\n",
    "    # define min max scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler1 = StandardScaler()\n",
    "    scaler2 = MaxAbsScaler()\n",
    "    scaler3 = RobustScaler()\n",
    "    scaler4 = Normalizer()\n",
    "    scaler5 = QuantileTransformer()\n",
    "    scaler6 = PowerTransformer()\n",
    "\n",
    "    # transform data\n",
    "    normalDf['ScaledDataAdjust-MinMax'] = scaler.fit_transform(normalDf[[columnName]])\n",
    "    normalDf['ScaledDataAdjust-StandardScaler'] = scaler1.fit_transform(normalDf[[columnName]])\n",
    "    normalDf['ScaledDataAdjust-MaxAbsScaler'] = scaler2.fit_transform(normalDf[[columnName]])   \n",
    "    normalDf['ScaledDataAdjust-RobustScaler'] = scaler3.fit_transform(normalDf[[columnName]])   \n",
    "    normalDf['ScaledDataAdjust-Normalizer'] = scaler4.fit_transform(normalDf[[columnName]])   \n",
    "    normalDf['ScaledDataAdjust-QuantileTransformer'] = scaler5.fit_transform(normalDf[[columnName]])\n",
    "    normalDf['ScaledDataAdjust-PowerTransformer'] = scaler6.fit_transform(normalDf[[columnName]])       \n",
    "    \n",
    "    return normalDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Release Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "releaseDf['90DayDate'] = releaseDf['Release Date'] + pd.DateOffset(days=120)\n",
    "\n",
    "releaseDf = DateTimeConvert(releaseDf,'90DayDate')\n",
    "releaseDf = DateTimeConvert(releaseDf,'Release Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instagram Hashtag Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_53460/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "instaHashtagDf = DateTimeConvert(instaHashtagDf,'RunDate')\n",
    "\n",
    "instaHashtagDf = DiffMaker(instaHashtagDf,'HashtagValue','RunDate')\n",
    "\n",
    "instaHashDf = RemoveData(releaseDf, instaHashtagDf)\n",
    "instaHashDf = NegativeDiffs(instaHashDf, 'diffs')\n",
    "instaHashDf['SocialMediaSource'] = 'InstagramHashtag'\n",
    "instaHashDf['SocialMediaValue'] = instaHashDf['zeroedDiffs']\n",
    "\n",
    "instaHashDf = NormalizeData(instaHashDf,'SocialMediaValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_53460/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "dailyTweetDf = DateTimeConvert(dailyTweetDf,'RunDate')\n",
    "dailyTweetDf = RemoveData(releaseDf, dailyTweetDf)\n",
    "dailyTweetDf['SocialMediaValue'] = dailyTweetDf['TweetCount'] + dailyTweetDf['RetweetCount']\n",
    "dailyTweetDf['SocialMediaSource'] = 'Tweets'\n",
    "dailyTweetDf = NormalizeData(dailyTweetDf,'SocialMediaValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reddit Comment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_53460/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "redditCommentsDf = DateTimeConvert(redditCommentsDf,'RunDate')\n",
    "redCommentDf = RemoveData(releaseDf, redditCommentsDf)\n",
    "redCommentDf['SocialMediaValue'] = redCommentDf['NumComments'] + redCommentDf['score']\n",
    "\n",
    "redCommentDf = redCommentDf[['TvShow','RunDate','SocialMediaValue']]\n",
    "iRedCommentDf = SumSocialMedia(redCommentDf, ['TvShow','RunDate'],1)\n",
    "iRedCommentDf['SocialMediaSource'] = 'RedditComments'\n",
    "\n",
    "iRedCommentDf = NormalizeData(iRedCommentDf,'SocialMediaValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instagram Account Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_53460/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "igAccountDf = DateTimeConvert(igAccountDf,'RunDate')\n",
    "\n",
    "igAccountDf = DiffMaker(igAccountDf,'IgAccountCounts','RunDate')\n",
    "\n",
    "\n",
    "instaAccDf = RemoveData(releaseDf, igAccountDf)\n",
    "instaAccDf = NegativeDiffs(instaAccDf, 'diffs')\n",
    "instaAccDf['SocialMediaSource'] = 'InstagramAccount'\n",
    "instaAccDf['SocialMediaValue'] = instaAccDf['zeroedDiffs']\n",
    "\n",
    "instaAccDf = NormalizeData(instaAccDf,'SocialMediaValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reddit Subscriber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_53460/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "redditSubsDf = DateTimeConvert(redditSubsDf,'RunDate')\n",
    "\n",
    "redditSubsDf = DiffMaker(redditSubsDf,'RedditSubs','RunDate')\n",
    "\n",
    "redSubDf = RemoveData(releaseDf, redditSubsDf)\n",
    "redSubDf = NegativeDiffs(redSubDf, 'diffs')\n",
    "redSubDf['SocialMediaSource'] = 'RedditSubscribers'\n",
    "redSubDf['SocialMediaValue'] = redSubDf['zeroedDiffs']\n",
    "\n",
    "redSubDf = NormalizeData(redSubDf,'SocialMediaValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Google Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_53460/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "googleDailyData = DateTimeConvert(googleDailyData,'RunDate')\n",
    "googDf1 = RemoveData(releaseDf, googleDailyData)\n",
    "googDf1 = NegativeDiffs(googDf1, 'GoogleValue')\n",
    "\n",
    "googDf1['SocialMediaSource'] = 'Google'\n",
    "googDf1['SocialMediaValue'] = googDf1['zeroedDiffs']\n",
    "\n",
    "googDf1 = NormalizeData(googDf1,'SocialMediaValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Release Date Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "releaseDateDf = DateTimeConvert(releaseDateDf,'EpisodeReleaseDate')\n",
    "iReleaseData = SumSocialMedia(releaseDateDf, ['TvShow','EpisodeReleaseDate'],0)\n",
    "iReleaseData['DailyReleaseCount'] = iReleaseData['EpisodeNumber']\n",
    "iReleaseData['RunDate'] = iReleaseData['EpisodeReleaseDate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time Value Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "instaAccDf = instaAccDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource','ScaledDataAdjust-MinMax','ScaledDataAdjust-StandardScaler',\n",
    "'ScaledDataAdjust-MaxAbsScaler','ScaledDataAdjust-RobustScaler','ScaledDataAdjust-Normalizer','ScaledDataAdjust-QuantileTransformer'\n",
    ",'ScaledDataAdjust-PowerTransformer']]#,'diffs']]\n",
    "redSubDf = redSubDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource','ScaledDataAdjust-MinMax','ScaledDataAdjust-StandardScaler',\n",
    "'ScaledDataAdjust-MaxAbsScaler','ScaledDataAdjust-RobustScaler','ScaledDataAdjust-Normalizer','ScaledDataAdjust-QuantileTransformer'\n",
    ",'ScaledDataAdjust-PowerTransformer']]#,'diffs']]\n",
    "dailyTweetDf = dailyTweetDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource','ScaledDataAdjust-MinMax','ScaledDataAdjust-StandardScaler',\n",
    "'ScaledDataAdjust-MaxAbsScaler','ScaledDataAdjust-RobustScaler','ScaledDataAdjust-Normalizer','ScaledDataAdjust-QuantileTransformer'\n",
    ",'ScaledDataAdjust-PowerTransformer']]#,'diffs']]\n",
    "instaHashDf = instaHashDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource','ScaledDataAdjust-MinMax','ScaledDataAdjust-StandardScaler',\n",
    "'ScaledDataAdjust-MaxAbsScaler','ScaledDataAdjust-RobustScaler','ScaledDataAdjust-Normalizer','ScaledDataAdjust-QuantileTransformer'\n",
    ",'ScaledDataAdjust-PowerTransformer']]#,'diffs']]\n",
    "googDf1 = googDf1[['TvShow','RunDate','SocialMediaValue','SocialMediaSource','ScaledDataAdjust-MinMax','ScaledDataAdjust-StandardScaler',\n",
    "'ScaledDataAdjust-MaxAbsScaler','ScaledDataAdjust-RobustScaler','ScaledDataAdjust-Normalizer','ScaledDataAdjust-QuantileTransformer'\n",
    ",'ScaledDataAdjust-PowerTransformer']]#,'diffs']]\n",
    "# reddit comment data is combined elsewhere\n",
    "iReleaseData = iReleaseData[['TvShow','RunDate','DailyReleaseCount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "uberDf2 = pd.concat([instaAccDf,redSubDf,dailyTweetDf,instaHashDf,googDf1,iRedCommentDf])\n",
    "\n",
    "uberDf3 = MergeDfs(uberDf2, releaseDf,'TvShow')\n",
    "uberDf3\n",
    "\n",
    "uberDf3 = MergeDfs(uberDf3, iReleaseData,['TvShow','RunDate'])\n",
    "uberDf3 = uberDf3[uberDf3['Ignore'] == 1]\n",
    "uberDf3 = uberDf3.fillna(0)\n",
    "uberDf3['PostReleaseDay'] = (uberDf3['RunDate'] - uberDf3['Release Date']).astype(str).str.replace(' days','').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output - individuals & uber dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "uberDf3 = uberDf3.sort_values(['TvShow','RunDate','SocialMediaSource'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "uberdf4= uberDf3[uberDf3['PostReleaseDay'] <= 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TvShow</th>\n",
       "      <th>RunDate</th>\n",
       "      <th>SocialMediaValue</th>\n",
       "      <th>SocialMediaSource</th>\n",
       "      <th>ScaledDataAdjust-MinMax</th>\n",
       "      <th>ScaledDataAdjust-StandardScaler</th>\n",
       "      <th>ScaledDataAdjust-MaxAbsScaler</th>\n",
       "      <th>ScaledDataAdjust-RobustScaler</th>\n",
       "      <th>ScaledDataAdjust-Normalizer</th>\n",
       "      <th>ScaledDataAdjust-QuantileTransformer</th>\n",
       "      <th>...</th>\n",
       "      <th>Stream</th>\n",
       "      <th>EpisodeCount</th>\n",
       "      <th>SeasonNumber</th>\n",
       "      <th>ReleaseCadence</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Ignore</th>\n",
       "      <th>ShowStatus</th>\n",
       "      <th>90DayDate</th>\n",
       "      <th>DailyReleaseCount</th>\n",
       "      <th>PostReleaseDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>17.64</td>\n",
       "      <td>Google</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.413910</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>1.335714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.824825</td>\n",
       "      <td>...</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Renewed</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>175.00</td>\n",
       "      <td>InstagramAccount</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>-0.165021</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.155973</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.582082</td>\n",
       "      <td>...</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Renewed</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>12.00</td>\n",
       "      <td>InstagramHashtag</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>-0.168522</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>-0.157895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.374875</td>\n",
       "      <td>...</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Renewed</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>2.00</td>\n",
       "      <td>RedditComments</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>-0.208537</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.234234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024525</td>\n",
       "      <td>...</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Renewed</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>154.00</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>-0.186378</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>-0.198792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162703</td>\n",
       "      <td>...</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Renewed</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26259</th>\n",
       "      <td>theEssexSerpent</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>50.00</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.188050</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.217829</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.092092</td>\n",
       "      <td>...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26262</th>\n",
       "      <td>theEssexSerpent</td>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>7.00</td>\n",
       "      <td>InstagramHashtag</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.170753</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.223684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.303303</td>\n",
       "      <td>...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26261</th>\n",
       "      <td>theEssexSerpent</td>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>25.00</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.188451</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.222405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.057558</td>\n",
       "      <td>...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26264</th>\n",
       "      <td>theEssexSerpent</td>\n",
       "      <td>2022-08-03</td>\n",
       "      <td>11.00</td>\n",
       "      <td>InstagramHashtag</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-0.168969</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-0.171053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363363</td>\n",
       "      <td>...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26263</th>\n",
       "      <td>theEssexSerpent</td>\n",
       "      <td>2022-08-03</td>\n",
       "      <td>38.00</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.188242</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.220026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.079580</td>\n",
       "      <td>...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-09-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24219 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TvShow    RunDate  SocialMediaValue SocialMediaSource  \\\n",
       "2150   ABlackLadySketchShow 2022-04-08             17.64            Google   \n",
       "2147   ABlackLadySketchShow 2022-04-08            175.00  InstagramAccount   \n",
       "2149   ABlackLadySketchShow 2022-04-08             12.00  InstagramHashtag   \n",
       "2151   ABlackLadySketchShow 2022-04-08              2.00    RedditComments   \n",
       "2148   ABlackLadySketchShow 2022-04-08            154.00            Tweets   \n",
       "...                     ...        ...               ...               ...   \n",
       "26259       theEssexSerpent 2022-08-01             50.00            Tweets   \n",
       "26262       theEssexSerpent 2022-08-02              7.00  InstagramHashtag   \n",
       "26261       theEssexSerpent 2022-08-02             25.00            Tweets   \n",
       "26264       theEssexSerpent 2022-08-03             11.00  InstagramHashtag   \n",
       "26263       theEssexSerpent 2022-08-03             38.00            Tweets   \n",
       "\n",
       "       ScaledDataAdjust-MinMax  ScaledDataAdjust-StandardScaler  \\\n",
       "2150                  0.176400                         0.413910   \n",
       "2147                  0.000783                        -0.165021   \n",
       "2149                  0.000302                        -0.168522   \n",
       "2151                  0.000057                        -0.208537   \n",
       "2148                  0.000061                        -0.186378   \n",
       "...                        ...                              ...   \n",
       "26259                 0.000020                        -0.188050   \n",
       "26262                 0.000176                        -0.170753   \n",
       "26261                 0.000010                        -0.188451   \n",
       "26264                 0.000277                        -0.168969   \n",
       "26263                 0.000015                        -0.188242   \n",
       "\n",
       "       ScaledDataAdjust-MaxAbsScaler  ScaledDataAdjust-RobustScaler  \\\n",
       "2150                        0.176400                       1.335714   \n",
       "2147                        0.000783                       0.155973   \n",
       "2149                        0.000302                      -0.157895   \n",
       "2151                        0.000013                      -0.234234   \n",
       "2148                        0.000061                      -0.198792   \n",
       "...                              ...                            ...   \n",
       "26259                       0.000020                      -0.217829   \n",
       "26262                       0.000176                      -0.223684   \n",
       "26261                       0.000010                      -0.222405   \n",
       "26264                       0.000277                      -0.171053   \n",
       "26263                       0.000015                      -0.220026   \n",
       "\n",
       "       ScaledDataAdjust-Normalizer  ScaledDataAdjust-QuantileTransformer  ...  \\\n",
       "2150                           1.0                              0.824825  ...   \n",
       "2147                           1.0                              0.582082  ...   \n",
       "2149                           1.0                              0.374875  ...   \n",
       "2151                           1.0                              0.024525  ...   \n",
       "2148                           1.0                              0.162703  ...   \n",
       "...                            ...                                   ...  ...   \n",
       "26259                          1.0                              0.092092  ...   \n",
       "26262                          1.0                              0.303303  ...   \n",
       "26261                          1.0                              0.057558  ...   \n",
       "26264                          1.0                              0.363363  ...   \n",
       "26263                          1.0                              0.079580  ...   \n",
       "\n",
       "       Stream EpisodeCount  SeasonNumber  ReleaseCadence Release Date Ignore  \\\n",
       "2150   HBOMax          6.0           3.0          Weekly   2022-04-08    1.0   \n",
       "2147   HBOMax          6.0           3.0          Weekly   2022-04-08    1.0   \n",
       "2149   HBOMax          6.0           3.0          Weekly   2022-04-08    1.0   \n",
       "2151   HBOMax          6.0           3.0          Weekly   2022-04-08    1.0   \n",
       "2148   HBOMax          6.0           3.0          Weekly   2022-04-08    1.0   \n",
       "...       ...          ...           ...             ...          ...    ...   \n",
       "26259   Apple          6.0           1.0          Hybrid   2022-05-13    1.0   \n",
       "26262   Apple          6.0           1.0          Hybrid   2022-05-13    1.0   \n",
       "26261   Apple          6.0           1.0          Hybrid   2022-05-13    1.0   \n",
       "26264   Apple          6.0           1.0          Hybrid   2022-05-13    1.0   \n",
       "26263   Apple          6.0           1.0          Hybrid   2022-05-13    1.0   \n",
       "\n",
       "       ShowStatus  90DayDate DailyReleaseCount  PostReleaseDay  \n",
       "2150      Renewed 2022-08-06               1.0               0  \n",
       "2147      Renewed 2022-08-06               1.0               0  \n",
       "2149      Renewed 2022-08-06               1.0               0  \n",
       "2151      Renewed 2022-08-06               1.0               0  \n",
       "2148      Renewed 2022-08-06               1.0               0  \n",
       "...           ...        ...               ...             ...  \n",
       "26259   Completed 2022-09-10               0.0              80  \n",
       "26262   Completed 2022-09-10               0.0              81  \n",
       "26261   Completed 2022-09-10               0.0              81  \n",
       "26264   Completed 2022-09-10               0.0              82  \n",
       "26263   Completed 2022-09-10               0.0              82  \n",
       "\n",
       "[24219 rows x 21 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uberdf4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filepath2 = r'/Users/cartersocha/Downloads/uberDataset5.csv'\n",
    "\n",
    "uberdf4.to_csv(filepath2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_tweets_by_show = uberdf4.groupby(['Stream','TvShow','SocialMediaSource']).max('PostReleaseDay')['PostReleaseDay']\n",
    "max_tweets_df = pd.DataFrame(max_tweets_by_show).reset_index().sort_values('PostReleaseDay', ascending=False)\n",
    "maxdfff = pd.DataFrame(max_tweets_df.groupby(['TvShow','SocialMediaSource']).max('PostReleaseDay')).reset_index()\n",
    "\n",
    "maxdfff[maxdfff['PostReleaseDay'] < 70]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
