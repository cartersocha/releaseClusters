{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filepath1 = r'/Users/cartersocha/Downloads/instgramHashtagCounts.xlsx'\n",
    "instaHashtagDf = pd.read_excel(filepath1)\n",
    "\n",
    "filepath2 = r'/Users/cartersocha/Downloads/tweetCountTest.xlsx'\n",
    "dailyTweetDf = pd.read_excel(filepath2)\n",
    "\n",
    "filepath3 = r'/Users/cartersocha/Desktop/ReleaseData.xlsx'\n",
    "releaseDf = pd.read_excel(filepath3, \"ShowInfoEndStart\")\n",
    "\n",
    "filepath4 = r'/Users/cartersocha/Downloads/instgramAccountCounts.xlsx'\n",
    "igAccountDf = pd.read_excel(filepath4)\n",
    "\n",
    "filepath5 = r'/Users/cartersocha/Downloads/redditCountTest.xlsx'\n",
    "redditSubsDf = pd.read_excel(filepath5)\n",
    "\n",
    "filepath6 = r'/Users/cartersocha/Downloads/redditCountFinal.txt'\n",
    "#redditCommentsDf = pd.read_excel(filepath6)\n",
    "\n",
    "filepath7 = r'/Users/cartersocha/Downloads/googleTvCount.xlsx'\n",
    "googleTrendsDf = pd.read_excel(filepath7)\n",
    "\n",
    "filepath8 = r'/Users/cartersocha/Desktop/ReleaseData.xlsx'\n",
    "releaseDateDf = pd.read_excel(filepath8, \"ReleaseDateData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DateTimeConvert(dateDf, dateColumn):\n",
    "    dateDf[dateColumn] = pd.to_datetime(dateDf[dateColumn])  \n",
    "\n",
    "    return dateDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiffMaker(fillnaDf, valueColumn, dateColumn):\n",
    "    fillnaDf.sort_values(['TvShow', dateColumn], inplace=True)\n",
    "\n",
    "    fillnaDf['diffs'] = fillnaDf.groupby(['TvShow'])[valueColumn].transform(lambda x: x.diff()).fillna(0)\n",
    "\n",
    "    fillnaDf.sort_index(inplace=True)\n",
    "\n",
    "    return fillnaDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveData(release,showDf):\n",
    "\n",
    "    bigDf = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(release)):\n",
    "        show = release['TvShow'][i]\n",
    "        firstDate = release['Release Date'][i]\n",
    "        secondDate = release['90DayDate'][i]\n",
    "\n",
    "        smallDf = showDf[showDf['TvShow'] == show]\n",
    "\n",
    "        newdf = smallDf[smallDf['RunDate'].between(firstDate, secondDate)]\n",
    "\n",
    "        bigDf = bigDf.append(newdf,ignore_index=True)\n",
    "\n",
    "    return bigDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergeDfs(mainDf, secondDf):\n",
    "\n",
    "    merged = pd.merge(mainDf,secondDf, how='outer', on=['TvShow'])\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def NegativeDiffs(diffDf,columnName):\n",
    "\n",
    "    diffDf[columnName] = np.where((diffDf[columnName] < 0), 0, diffDf[columnName])\n",
    "\n",
    "    return diffDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SumSocialMedia(sumDf,columnName):\n",
    "\n",
    "    summarizedDf = sumDf.groupby(columnName, as_index=False).sum()\n",
    "    summarizedDf = pd.DataFrame(summarizedDf)\n",
    "\n",
    "    return summarizedDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Release Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "releaseDf['90DayDate'] = releaseDf['Release Date'] + pd.DateOffset(days=90)\n",
    "\n",
    "releaseDf = DateTimeConvert(releaseDf,'90DayDate')\n",
    "releaseDf = DateTimeConvert(releaseDf,'Release Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instagram Hashtag Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_3459/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "instaHashtagDf = DateTimeConvert(instaHashtagDf,'RunDate')\n",
    "\n",
    "instaHashtagDf = DiffMaker(instaHashtagDf,'HashtagValue','RunDate')\n",
    "\n",
    "instaHashDf = RemoveData(releaseDf, instaHashtagDf)\n",
    "instaHashDf = NegativeDiffs(instaHashDf, 'diffs')\n",
    "instaHashDf['SocialMediaSource'] = 'InstagramHashtag'\n",
    "instaHashDf['SocialMediaValue'] = instaHashDf['diffs']\n",
    "\n",
    "iHashtagDf = SumSocialMedia(instaHashDf, 'TvShow')\n",
    "\n",
    "iHashtagDf['SocialMediaValue'] = iHashtagDf['diffs']\n",
    "iHashtagDf['SocialMediaSource'] = 'InstagramHashtag'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_3459/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "dailyTweetDf = DateTimeConvert(dailyTweetDf,'RunDate')\n",
    "dailyTweetDf = RemoveData(releaseDf, dailyTweetDf)\n",
    "dailyTweetDf['SocialMediaValue'] = dailyTweetDf['TweetCount'] + dailyTweetDf['RetweetCount']\n",
    "dailyTweetDf['SocialMediaSource'] = 'Tweets'\n",
    "\n",
    "iTweetCountDf = SumSocialMedia(dailyTweetDf, 'TvShow')\n",
    "iTweetCountDf['SocialMediaSource'] = 'Tweets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reddit Comment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "redditCommentsDf = DateTimeConvert(redditCommentsDf,'runDate')\n",
    "\n",
    "redCommentDf = RemoveData(releaseDf, redditCommentsDf)\n",
    "\n",
    "\n",
    "iRedCommentDf = SumSocialMedia(redCommentDf, 'TvShow')\n",
    "iRedCommentDf['SocialMediaValue'] = redCommentDf['NumComments'] + redCommentDf['score']\n",
    "iRedCommentDf['SocialMediaSource'] = 'RedditComments'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instagram Account Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_3459/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "igAccountDf = DateTimeConvert(igAccountDf,'RunDate')\n",
    "\n",
    "igAccountDf = DiffMaker(igAccountDf,'IgAccountCounts','RunDate')\n",
    "\n",
    "\n",
    "instaAccDf = RemoveData(releaseDf, igAccountDf)\n",
    "instaAccDf = NegativeDiffs(instaAccDf, 'diffs')\n",
    "instaAccDf['SocialMediaSource'] = 'InstagramAccount'\n",
    "instaAccDf['SocialMediaValue'] = instaAccDf['diffs']\n",
    "\n",
    "iAccountDf = SumSocialMedia(instaAccDf, 'TvShow')\n",
    "\n",
    "iAccountDf['SocialMediaValue'] = iAccountDf['diffs']\n",
    "iAccountDf['SocialMediaSource'] = 'InstagramAccount'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reddit Subscriber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_3459/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "redditSubsDf = DateTimeConvert(redditSubsDf,'RunDate')\n",
    "\n",
    "redditSubsDf = DiffMaker(redditSubsDf,'RedditSubs','RunDate')\n",
    "\n",
    "redSubDf = RemoveData(releaseDf, redditSubsDf)\n",
    "redSubDf = NegativeDiffs(redSubDf, 'diffs')\n",
    "redSubDf['SocialMediaSource'] = 'RedditSubscribers'\n",
    "redSubDf['SocialMediaValue'] = redSubDf['diffs']\n",
    "\n",
    "iRedSubDf = SumSocialMedia(redSubDf, 'TvShow')\n",
    "iRedSubDf['SocialMediaValue'] = iRedSubDf['diffs']\n",
    "iRedSubDf['SocialMediaSource'] = 'RedditSubscribers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Google Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_3459/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "googleTrendsDf = DateTimeConvert(googleTrendsDf,'RunDate')\n",
    "\n",
    "googDf = RemoveData(releaseDf, googleTrendsDf)\n",
    "googDf = NegativeDiffs(googDf, 'GoogleValue')\n",
    "googDf['SocialMediaSource'] = 'Google'\n",
    "googDf['SocialMediaValue'] = googDf['GoogleValue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Release Date Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TvShow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_3459/2818332571.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreleaseDateDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDateTimeConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreleaseDateDf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'EpisodeReleaseDate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miReleaseData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSumSocialMedia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreleaseDateDf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'TvShow'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'EpisodeReleaseDate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_3459/3892806876.py\u001b[0m in \u001b[0;36mSumSocialMedia\u001b[0;34m(sumDf, columnName)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mSumSocialMedia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumDf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumnName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msummarizedDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msumDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumnName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msummarizedDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarizedDf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   7712\u001b[0m         \u001b[0;31m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7713\u001b[0m         \u001b[0;31m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7714\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   7715\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7716\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    883\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    880\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TvShow'"
     ]
    }
   ],
   "source": [
    "releaseDateDf = DateTimeConvert(releaseDateDf,'EpisodeReleaseDate')\n",
    "iReleaseData = SumSocialMedia(releaseDateDf, ['TvShow','EpisodeReleaseDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time Value Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instaAccDf = instaAccDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource']]\n",
    "redSubDf = redSubDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource']]\n",
    "dailyTweetDf = dailyTweetDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource']]\n",
    "instaHashDf = instaHashDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource']]\n",
    "googDf = googDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TvShow</th>\n",
       "      <th>RunDate</th>\n",
       "      <th>SocialMediaValue</th>\n",
       "      <th>SocialMediaSource</th>\n",
       "      <th>Stream</th>\n",
       "      <th>EpisodeCount</th>\n",
       "      <th>SeasonNumber</th>\n",
       "      <th>ReleaseCadence</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Cancel</th>\n",
       "      <th>90DayDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>175.0</td>\n",
       "      <td>InstagramAccount</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-09</td>\n",
       "      <td>341.0</td>\n",
       "      <td>InstagramAccount</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-10</td>\n",
       "      <td>327.0</td>\n",
       "      <td>InstagramAccount</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>222.0</td>\n",
       "      <td>InstagramAccount</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>150.0</td>\n",
       "      <td>InstagramAccount</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-13</td>\n",
       "      <td>71.0</td>\n",
       "      <td>InstagramAccount</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-14</td>\n",
       "      <td>85.0</td>\n",
       "      <td>InstagramAccount</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-15</td>\n",
       "      <td>73.0</td>\n",
       "      <td>InstagramAccount</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>116.0</td>\n",
       "      <td>InstagramAccount</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABlackLadySketchShow</td>\n",
       "      <td>2022-04-17</td>\n",
       "      <td>125.0</td>\n",
       "      <td>InstagramAccount</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TvShow    RunDate  SocialMediaValue SocialMediaSource  \\\n",
       "0  ABlackLadySketchShow 2022-04-08             175.0  InstagramAccount   \n",
       "1  ABlackLadySketchShow 2022-04-09             341.0  InstagramAccount   \n",
       "2  ABlackLadySketchShow 2022-04-10             327.0  InstagramAccount   \n",
       "3  ABlackLadySketchShow 2022-04-11             222.0  InstagramAccount   \n",
       "4  ABlackLadySketchShow 2022-04-12             150.0  InstagramAccount   \n",
       "5  ABlackLadySketchShow 2022-04-13              71.0  InstagramAccount   \n",
       "6  ABlackLadySketchShow 2022-04-14              85.0  InstagramAccount   \n",
       "7  ABlackLadySketchShow 2022-04-15              73.0  InstagramAccount   \n",
       "8  ABlackLadySketchShow 2022-04-16             116.0  InstagramAccount   \n",
       "9  ABlackLadySketchShow 2022-04-17             125.0  InstagramAccount   \n",
       "\n",
       "   Stream  EpisodeCount  SeasonNumber ReleaseCadence Release Date  Cancel  \\\n",
       "0  HBOMax           6.0           3.0         Weekly   2022-04-08     NaN   \n",
       "1  HBOMax           6.0           3.0         Weekly   2022-04-08     NaN   \n",
       "2  HBOMax           6.0           3.0         Weekly   2022-04-08     NaN   \n",
       "3  HBOMax           6.0           3.0         Weekly   2022-04-08     NaN   \n",
       "4  HBOMax           6.0           3.0         Weekly   2022-04-08     NaN   \n",
       "5  HBOMax           6.0           3.0         Weekly   2022-04-08     NaN   \n",
       "6  HBOMax           6.0           3.0         Weekly   2022-04-08     NaN   \n",
       "7  HBOMax           6.0           3.0         Weekly   2022-04-08     NaN   \n",
       "8  HBOMax           6.0           3.0         Weekly   2022-04-08     NaN   \n",
       "9  HBOMax           6.0           3.0         Weekly   2022-04-08     NaN   \n",
       "\n",
       "   90DayDate  \n",
       "0 2022-07-07  \n",
       "1 2022-07-07  \n",
       "2 2022-07-07  \n",
       "3 2022-07-07  \n",
       "4 2022-07-07  \n",
       "5 2022-07-07  \n",
       "6 2022-07-07  \n",
       "7 2022-07-07  \n",
       "8 2022-07-07  \n",
       "9 2022-07-07  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uberDf2 = pd.concat([instaAccDf,redSubDf,dailyTweetDf,instaHashDf,googDf])\n",
    "\n",
    "uberDf3 = MergeDfs(uberDf2, releaseDf)\n",
    "uberDf3 = uberDf3[uberDf3['Cancel'] != 0]\n",
    "uberDf3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "igAccount = iAccountDf[['TvShow','SocialMediaValue','SocialMediaSource']]\n",
    "redditSub = iRedSubDf[['TvShow','SocialMediaValue','SocialMediaSource']]\n",
    "tweetComments = iTweetCountDf[['TvShow','SocialMediaValue','SocialMediaSource']]\n",
    "igHashtag = iHashtagDf[['TvShow','SocialMediaValue','SocialMediaSource']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuberData = pd.concat([igAccount,redditSub,tweetComments,igHashtag],axis=0)\n",
    "nuberData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uberDf = MergeDfs(releaseDf, iHashtagDf)\n",
    "\n",
    "uberDf = MergeDfs(uberDf, iTweetCountDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uberDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output - individuals & uber dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filepath2 = r'/Users/cartersocha/Downloads/uberDataset.csv'\n",
    "\n",
    "uberDf3.to_csv(filepath2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
