{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filepath1 = r'/Users/cartersocha/Downloads/instgramHashtagCounts.xlsx'\n",
    "instaHashtagDf = pd.read_excel(filepath1)\n",
    "\n",
    "filepath2 = r'/Users/cartersocha/Downloads/tweetCountTest.xlsx'\n",
    "dailyTweetDf = pd.read_excel(filepath2)\n",
    "\n",
    "filepath3 = r'/Users/cartersocha/Desktop/ReleaseData.xlsx'\n",
    "releaseDf = pd.read_excel(filepath3, \"ShowInfoEndStart\")\n",
    "\n",
    "filepath4 = r'/Users/cartersocha/Downloads/instgramAccountCounts.xlsx'\n",
    "igAccountDf = pd.read_excel(filepath4)\n",
    "\n",
    "filepath5 = r'/Users/cartersocha/Downloads/redditCountTest.xlsx'\n",
    "redditSubsDf = pd.read_excel(filepath5)\n",
    "\n",
    "filepath6 = r'/Users/cartersocha/Downloads/redditCommentData.xlsx'\n",
    "#redditCommentsDf = pd.read_excel(filepath6)\n",
    "\n",
    "filepath7 = r'/Users/cartersocha/Downloads/googleTvCount.xlsx'\n",
    "googleTrendsDf = pd.read_excel(filepath7)\n",
    "\n",
    "filepath8 = r'/Users/cartersocha/Desktop/ReleaseData.xlsx'\n",
    "releaseDateDf = pd.read_excel(filepath8, \"ReleaseDateData\")\n",
    "\n",
    "filepath10 = r'/Users/cartersocha/Downloads/googleDataset.csv'\n",
    "googleDailyData = pd.read_csv(filepath10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DateTimeConvert(dateDf, dateColumn):\n",
    "    dateDf[dateColumn] = pd.to_datetime(dateDf[dateColumn])  \n",
    "\n",
    "    return dateDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiffMaker(fillnaDf, valueColumn, dateColumn):\n",
    "    fillnaDf.sort_values(['TvShow', dateColumn], inplace=True)\n",
    "\n",
    "    fillnaDf['diffs'] = fillnaDf.groupby(['TvShow'])[valueColumn].transform(lambda x: x.diff()).fillna(0)\n",
    "\n",
    "    fillnaDf.sort_index(inplace=True)\n",
    "\n",
    "    return fillnaDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveData(release,showDf):\n",
    "\n",
    "    bigDf = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(release)):\n",
    "        show = release['TvShow'][i]\n",
    "        firstDate = release['Release Date'][i]\n",
    "        secondDate = release['90DayDate'][i]\n",
    "\n",
    "        smallDf = showDf[showDf['TvShow'] == show]\n",
    "\n",
    "        newdf = smallDf[smallDf['RunDate'].between(firstDate, secondDate)]\n",
    "\n",
    "        bigDf = bigDf.append(newdf,ignore_index=True)\n",
    "\n",
    "    return bigDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergeDfs(mainDf, secondDf, columnName):\n",
    "\n",
    "    merged = pd.merge(mainDf,secondDf, how='outer', on=columnName)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def NegativeDiffs(diffDf,columnName):\n",
    "\n",
    "    diffDf['zeroedDiffs'] = np.where((diffDf[columnName] < 0), 0, diffDf[columnName])\n",
    "\n",
    "    return diffDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SumSocialMedia(sumDf,columnName):\n",
    "    # check to see if this is episode count or generic summarization\n",
    "    if type(columnName) != list:\n",
    "        summarizedDf = sumDf.groupby(columnName, as_index=False).sum()\n",
    "        summarizedDf = pd.DataFrame(summarizedDf)\n",
    "    \n",
    "    summarizedDf = sumDf.groupby(columnName, as_index=False).count()\n",
    "    summarizedDf = pd.DataFrame(summarizedDf)\n",
    "    \n",
    "    return summarizedDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Release Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "releaseDf['90DayDate'] = releaseDf['Release Date'] + pd.DateOffset(days=120)\n",
    "\n",
    "releaseDf = DateTimeConvert(releaseDf,'90DayDate')\n",
    "releaseDf = DateTimeConvert(releaseDf,'Release Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instagram Hashtag Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_11479/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "instaHashtagDf = DateTimeConvert(instaHashtagDf,'RunDate')\n",
    "\n",
    "instaHashtagDf = DiffMaker(instaHashtagDf,'HashtagValue','RunDate')\n",
    "\n",
    "instaHashDf = RemoveData(releaseDf, instaHashtagDf)\n",
    "instaHashDf = NegativeDiffs(instaHashDf, 'diffs')\n",
    "instaHashDf['SocialMediaSource'] = 'InstagramHashtag'\n",
    "instaHashDf['SocialMediaValue'] = instaHashDf['zeroedDiffs']\n",
    "\n",
    "#iHashtagDf = SumSocialMedia(instaHashDf, 'TvShow')\n",
    "\n",
    "#iHashtagDf['SocialMediaValue'] = iHashtagDf['zeroedDiffs']\n",
    "#iHashtagDf['SocialMediaSource'] = 'InstagramHashtag'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_11479/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "dailyTweetDf = DateTimeConvert(dailyTweetDf,'RunDate')\n",
    "dailyTweetDf = RemoveData(releaseDf, dailyTweetDf)\n",
    "dailyTweetDf['SocialMediaValue'] = dailyTweetDf['TweetCount'] + dailyTweetDf['RetweetCount']\n",
    "dailyTweetDf['SocialMediaSource'] = 'Tweets'\n",
    "\n",
    "#iTweetCountDf = SumSocialMedia(dailyTweetDf, 'TvShow')\n",
    "#iTweetCountDf['SocialMediaSource'] = 'Tweets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reddit Comment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_11479/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "redditCommentsDf['TvShow'] = redditCommentsDf['Show']\n",
    "redditCommentsDf['RunDate'] = redditCommentsDf['runDate']\n",
    "redditCommentsDf = DateTimeConvert(redditCommentsDf,'RunDate')\n",
    "\n",
    "redCommentDf = RemoveData(releaseDf, redditCommentsDf)\n",
    "redCommentDf['SocialMediaValue'] = redCommentDf['NumComments'] + redCommentDf['score']\n",
    "redCommentDf['SocialMediaSource'] = 'RedditComments'\n",
    "\n",
    "#iRedCommentDf = SumSocialMedia(redCommentDf, ['TvShow','RunDate'])\n",
    "#iRedCommentDf['SocialMediaValue'] = redCommentDf['NumComments'] + redCommentDf['score']\n",
    "#iRedCommentDf['SocialMediaSource'] = 'RedditComments'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instagram Account Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_11479/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "igAccountDf = DateTimeConvert(igAccountDf,'RunDate')\n",
    "\n",
    "igAccountDf = DiffMaker(igAccountDf,'IgAccountCounts','RunDate')\n",
    "\n",
    "\n",
    "instaAccDf = RemoveData(releaseDf, igAccountDf)\n",
    "instaAccDf = NegativeDiffs(instaAccDf, 'diffs')\n",
    "instaAccDf['SocialMediaSource'] = 'InstagramAccount'\n",
    "instaAccDf['SocialMediaValue'] = instaAccDf['zeroedDiffs']\n",
    "\n",
    "#iAccountDf = SumSocialMedia(instaAccDf, 'TvShow')\n",
    "\n",
    "#iAccountDf['SocialMediaValue'] = iAccountDf['zeroedDiffs']\n",
    "#iAccountDf['SocialMediaSource'] = 'InstagramAccount'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reddit Subscriber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_11479/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "redditSubsDf = DateTimeConvert(redditSubsDf,'RunDate')\n",
    "\n",
    "redditSubsDf = DiffMaker(redditSubsDf,'RedditSubs','RunDate')\n",
    "\n",
    "redSubDf = RemoveData(releaseDf, redditSubsDf)\n",
    "redSubDf = NegativeDiffs(redSubDf, 'diffs')\n",
    "redSubDf['SocialMediaSource'] = 'RedditSubscribers'\n",
    "redSubDf['SocialMediaValue'] = redSubDf['zeroedDiffs']\n",
    "\n",
    "#iRedSubDf = SumSocialMedia(redSubDf, 'TvShow')\n",
    "#iRedSubDf['SocialMediaValue'] = iRedSubDf['zeroedDiffs']\n",
    "#iRedSubDf['SocialMediaSource'] = 'RedditSubscribers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Google Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "googleTrendsDf = DateTimeConvert(googleTrendsDf,'RunDate')\n",
    "\n",
    "googDf = RemoveData(releaseDf, googleTrendsDf)\n",
    "googDf = NegativeDiffs(googDf, 'GoogleValue')\n",
    "googDf['SocialMediaSource'] = 'Google'\n",
    "googDf['SocialMediaValue'] = googDf['zeroedDiffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_11479/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "googleDailyData = DateTimeConvert(googleDailyData,'RunDate')\n",
    "googDf1 = RemoveData(releaseDf, googleDailyData)\n",
    "googDf1 = NegativeDiffs(googDf1, 'GoogleValue')\n",
    "googDf1['SocialMediaSource'] = 'Google'\n",
    "googDf1['SocialMediaValue'] = googDf1['zeroedDiffs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Release Date Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "releaseDateDf = DateTimeConvert(releaseDateDf,'EpisodeReleaseDate')\n",
    "iReleaseData = SumSocialMedia(releaseDateDf, ['TvShow','EpisodeReleaseDate'])\n",
    "iReleaseData['DailyReleaseCount'] = iReleaseData['EpisodeNumber']\n",
    "iReleaseData['RunDate'] = iReleaseData['EpisodeReleaseDate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time Value Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "instaAccDf = instaAccDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource','diffs']]\n",
    "redSubDf = redSubDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource','diffs']]\n",
    "dailyTweetDf = dailyTweetDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource']]\n",
    "instaHashDf = instaHashDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource','diffs']]\n",
    "#googDf = googDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource']]\n",
    "googDf1 = googDf1[['TvShow','RunDate','SocialMediaValue','SocialMediaSource']]\n",
    "#redCommentDf = redCommentDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource']]\n",
    "iReleaseData = iReleaseData[['TvShow','RunDate','DailyReleaseCount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TvShow</th>\n",
       "      <th>RunDate</th>\n",
       "      <th>SocialMediaValue</th>\n",
       "      <th>SocialMediaSource</th>\n",
       "      <th>diffs</th>\n",
       "      <th>Stream</th>\n",
       "      <th>EpisodeCount</th>\n",
       "      <th>SeasonNumber</th>\n",
       "      <th>ReleaseCadence</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Ignore</th>\n",
       "      <th>ShowStatus</th>\n",
       "      <th>90DayDate</th>\n",
       "      <th>DailyReleaseCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MoonKnight</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>2481.0</td>\n",
       "      <td>InstagramAccount</td>\n",
       "      <td>2481.0</td>\n",
       "      <td>Disney</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MoonKnight</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>134.0</td>\n",
       "      <td>RedditSubscribers</td>\n",
       "      <td>134.0</td>\n",
       "      <td>Disney</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MoonKnight</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>165358.0</td>\n",
       "      <td>Tweets</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Disney</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MoonKnight</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>2913.0</td>\n",
       "      <td>InstagramHashtag</td>\n",
       "      <td>2913.0</td>\n",
       "      <td>Disney</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MoonKnight</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Google</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Disney</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Weekly</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24041</th>\n",
       "      <td>AboutLastNighthbo</td>\n",
       "      <td>2022-06-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>InstagramHashtag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Binge</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undecided</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24042</th>\n",
       "      <td>AboutLastNighthbo</td>\n",
       "      <td>2022-06-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>InstagramHashtag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Binge</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undecided</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24043</th>\n",
       "      <td>AboutLastNighthbo</td>\n",
       "      <td>2022-06-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>InstagramHashtag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Binge</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undecided</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24044</th>\n",
       "      <td>AboutLastNighthbo</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>InstagramHashtag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Binge</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undecided</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24045</th>\n",
       "      <td>AboutLastNighthbo</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>InstagramHashtag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HBOMax</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Binge</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Undecided</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22729 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TvShow    RunDate  SocialMediaValue  SocialMediaSource  \\\n",
       "0             MoonKnight 2022-03-30            2481.0   InstagramAccount   \n",
       "1             MoonKnight 2022-03-30             134.0  RedditSubscribers   \n",
       "2             MoonKnight 2022-03-30          165358.0             Tweets   \n",
       "3             MoonKnight 2022-03-30            2913.0   InstagramHashtag   \n",
       "4             MoonKnight 2022-03-30              64.0             Google   \n",
       "...                  ...        ...               ...                ...   \n",
       "24041  AboutLastNighthbo 2022-06-04               0.0   InstagramHashtag   \n",
       "24042  AboutLastNighthbo 2022-06-05               0.0   InstagramHashtag   \n",
       "24043  AboutLastNighthbo 2022-06-07               0.0   InstagramHashtag   \n",
       "24044  AboutLastNighthbo 2022-06-08               0.0   InstagramHashtag   \n",
       "24045  AboutLastNighthbo 2022-06-10               0.0   InstagramHashtag   \n",
       "\n",
       "        diffs  Stream  EpisodeCount  SeasonNumber ReleaseCadence Release Date  \\\n",
       "0      2481.0  Disney           6.0           1.0         Weekly   2022-03-30   \n",
       "1       134.0  Disney           6.0           1.0         Weekly   2022-03-30   \n",
       "2         0.0  Disney           6.0           1.0         Weekly   2022-03-30   \n",
       "3      2913.0  Disney           6.0           1.0         Weekly   2022-03-30   \n",
       "4         0.0  Disney           6.0           1.0         Weekly   2022-03-30   \n",
       "...       ...     ...           ...           ...            ...          ...   \n",
       "24041     0.0  HBOMax           8.0           1.0          Binge   2022-02-10   \n",
       "24042     0.0  HBOMax           8.0           1.0          Binge   2022-02-10   \n",
       "24043     0.0  HBOMax           8.0           1.0          Binge   2022-02-10   \n",
       "24044     0.0  HBOMax           8.0           1.0          Binge   2022-02-10   \n",
       "24045     0.0  HBOMax           8.0           1.0          Binge   2022-02-10   \n",
       "\n",
       "       Ignore ShowStatus  90DayDate  DailyReleaseCount  \n",
       "0         1.0  Completed 2022-07-28                1.0  \n",
       "1         1.0  Completed 2022-07-28                1.0  \n",
       "2         1.0  Completed 2022-07-28                1.0  \n",
       "3         1.0  Completed 2022-07-28                1.0  \n",
       "4         1.0  Completed 2022-07-28                1.0  \n",
       "...       ...        ...        ...                ...  \n",
       "24041     1.0  Undecided 2022-06-10                0.0  \n",
       "24042     1.0  Undecided 2022-06-10                0.0  \n",
       "24043     1.0  Undecided 2022-06-10                0.0  \n",
       "24044     1.0  Undecided 2022-06-10                0.0  \n",
       "24045     1.0  Undecided 2022-06-10                0.0  \n",
       "\n",
       "[22729 rows x 14 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uberDf2 = pd.concat([instaAccDf,redSubDf,dailyTweetDf,instaHashDf,googDf1])\n",
    "\n",
    "uberDf3 = MergeDfs(uberDf2, releaseDf,'TvShow')\n",
    "uberDf3\n",
    "\n",
    "uberDf3 = MergeDfs(uberDf3, iReleaseData,['TvShow','RunDate'])\n",
    "uberDf3 = uberDf3[uberDf3['Ignore'] == 1]\n",
    "uberDf3 = uberDf3.fillna(0)\n",
    "uberDf3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "igAccount = iAccountDf[['TvShow','SocialMediaValue','SocialMediaSource']]\n",
    "redditSub = iRedSubDf[['TvShow','SocialMediaValue','SocialMediaSource']]\n",
    "tweetComments = iTweetCountDf[['TvShow','SocialMediaValue','SocialMediaSource']]\n",
    "igHashtag = iHashtagDf[['TvShow','SocialMediaValue','SocialMediaSource']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuberData = pd.concat([igAccount,redditSub,tweetComments,igHashtag],axis=0)\n",
    "nuberData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uberDf = MergeDfs(releaseDf, iHashtagDf)\n",
    "\n",
    "uberDf = MergeDfs(uberDf, iTweetCountDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uberDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output - individuals & uber dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath2 = r'/Users/cartersocha/Downloads/uberDataset.csv'\n",
    "\n",
    "uberDf3.to_csv(filepath2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
