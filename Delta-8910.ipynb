{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "filepath1 = r'/Users/cartersocha/Downloads/instgramHashtagCounts.xlsx'\n",
    "instaHashtagDf = pd.read_excel(filepath1)\n",
    "\n",
    "filepath2 = r'/Users/cartersocha/Downloads/tweetCountTest.xlsx'\n",
    "dailyTweetDf = pd.read_excel(filepath2)\n",
    "\n",
    "filepath3 = r'/Users/cartersocha/Desktop/ReleaseData.xlsx'\n",
    "releaseDf = pd.read_excel(filepath3, \"ShowInfoEndStart\")\n",
    "\n",
    "filepath4 = r'/Users/cartersocha/Downloads/instgramAccountCounts.xlsx'\n",
    "igAccountDf = pd.read_excel(filepath4)\n",
    "\n",
    "filepath5 = r'/Users/cartersocha/Downloads/redditCountTest.xlsx'\n",
    "redditSubsDf = pd.read_excel(filepath5)\n",
    "\n",
    "filepath6 = r'/Users/cartersocha/Downloads/redditCommentCombo.csv'\n",
    "redditCommentsDf = pd.read_csv(filepath6)\n",
    "\n",
    "filepath8 = r'/Users/cartersocha/Desktop/ReleaseData.xlsx'\n",
    "releaseDateDf = pd.read_excel(filepath8, \"ReleaseDateData\")\n",
    "\n",
    "filepath10 = r'/Users/cartersocha/Downloads/googleDataset2.csv'\n",
    "googleDailyData = pd.read_csv(filepath10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DateTimeConvert(dateDf, dateColumn):\n",
    "    dateDf[dateColumn] = pd.to_datetime(dateDf[dateColumn])  \n",
    "\n",
    "    return dateDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiffMaker(fillnaDf, valueColumn, dateColumn):\n",
    "    fillnaDf.sort_values(['TvShow', dateColumn], inplace=True)\n",
    "\n",
    "    fillnaDf['diffs'] = fillnaDf.groupby(['TvShow'])[valueColumn].transform(lambda x: x.diff()).fillna(0)\n",
    "\n",
    "    fillnaDf.sort_index(inplace=True)\n",
    "\n",
    "    return fillnaDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveData(release,showDf):\n",
    "\n",
    "    bigDf = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(release)):\n",
    "        show = release['TvShow'][i]\n",
    "        firstDate = release['Release Date'][i]\n",
    "        secondDate = release['90DayDate'][i]\n",
    "\n",
    "        smallDf = showDf[showDf['TvShow'] == show]\n",
    "\n",
    "        newdf = smallDf[smallDf['RunDate'].between(firstDate, secondDate)]\n",
    "\n",
    "        bigDf = bigDf.append(newdf,ignore_index=True)\n",
    "\n",
    "    return bigDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergeDfs(mainDf, secondDf, columnName):\n",
    "\n",
    "    merged = pd.merge(mainDf,secondDf, how='outer', on=columnName)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def NegativeDiffs(diffDf,columnName):\n",
    "\n",
    "    diffDf['zeroedDiffs'] = np.where((diffDf[columnName] < 0), 0, diffDf[columnName])\n",
    "\n",
    "    return diffDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SumSocialMedia(sumDf,columnName,trigger):\n",
    "    # check to see if this is episode count or generic summarization\n",
    "    if trigger == 1:\n",
    "        summarizedDf = sumDf.groupby(columnName, as_index=False).sum()\n",
    "        summarizedDf = pd.DataFrame(summarizedDf)\n",
    "    \n",
    "    else:\n",
    "        summarizedDf = sumDf.groupby(columnName, as_index=False).count()\n",
    "        summarizedDf = pd.DataFrame(summarizedDf)\n",
    "    \n",
    "    return summarizedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def NormalizeData(normalDf,columnName):\n",
    "\n",
    "    # define min max scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    # transform data\n",
    "    scaledSeries = scaler.fit_transform(normalDf[[columnName]])\n",
    "    \n",
    "    return scaledSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Release Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "releaseDf['90DayDate'] = releaseDf['Release Date'] + pd.DateOffset(days=90)\n",
    "\n",
    "releaseDf = DateTimeConvert(releaseDf,'90DayDate')\n",
    "releaseDf = DateTimeConvert(releaseDf,'Release Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Google Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_52241/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "googleDailyData = DateTimeConvert(googleDailyData,'RunDate')\n",
    "googDf1 = RemoveData(releaseDf, googleDailyData)\n",
    "googDf1 = NegativeDiffs(googDf1, 'GoogleValue')\n",
    "\n",
    "googDf1['GoogleValue'] = googDf1['zeroedDiffs']\n",
    "\n",
    "googDf1['ScaledDataAdjust'] = NormalizeData(googDf1,'GoogleValue')\n",
    "\n",
    "googDf1['ScaledGoogleValue'] = googDf1['ScaledDataAdjust']\n",
    "\n",
    "googDf1 = googDf1[['TvShow','RunDate','GoogleValue','ScaledGoogleValue']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instagram Hashtag Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_52241/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "instaHashtagDf = DateTimeConvert(instaHashtagDf,'RunDate')\n",
    "\n",
    "instaHashtagDf = DiffMaker(instaHashtagDf,'HashtagValue','RunDate')\n",
    "\n",
    "instaHashDf = RemoveData(releaseDf, instaHashtagDf)\n",
    "instaHashDf = NegativeDiffs(instaHashDf, 'diffs')\n",
    "instaHashDf['SocialMediaSource'] = 'InstagramHashtag'\n",
    "instaHashDf['SocialMediaValue'] = instaHashDf['zeroedDiffs']\n",
    "\n",
    "instaHashDf = MergeDfs(instaHashDf, googDf1,['TvShow','RunDate'])\n",
    "instaHashDf = instaHashDf.fillna(0)\n",
    "instaHashDf = instaHashDf[instaHashDf['SocialMediaSource'] != 0]\n",
    "instaHashDf['GoogleAdjustedSocial'] = (instaHashDf['SocialMediaValue'] * instaHashDf['ScaledGoogleValue']) + instaHashDf['SocialMediaValue']\n",
    "\n",
    "instaHashDf['ScaledDataAdjustGoogle'] = NormalizeData(instaHashDf,'GoogleAdjustedSocial')\n",
    "instaHashDf['ScaledDataAdjust'] = NormalizeData(instaHashDf,'SocialMediaValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_52241/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "dailyTweetDf = DateTimeConvert(dailyTweetDf,'RunDate')\n",
    "dailyTweetDf = RemoveData(releaseDf, dailyTweetDf)\n",
    "dailyTweetDf['SocialMediaValue'] = dailyTweetDf['TweetCount'] + dailyTweetDf['RetweetCount']\n",
    "dailyTweetDf['SocialMediaSource'] = 'Tweets'\n",
    "\n",
    "dailyTweetDf = MergeDfs(dailyTweetDf, googDf1,['TvShow','RunDate'])\n",
    "dailyTweetDf = dailyTweetDf.fillna(0)\n",
    "dailyTweetDf = dailyTweetDf[dailyTweetDf['SocialMediaSource'] != 0]\n",
    "dailyTweetDf['GoogleAdjustedSocial'] = (dailyTweetDf['SocialMediaValue'] * dailyTweetDf['ScaledGoogleValue']) + dailyTweetDf['SocialMediaValue']\n",
    "\n",
    "dailyTweetDf['ScaledDataAdjustGoogle'] = NormalizeData(dailyTweetDf,'GoogleAdjustedSocial')\n",
    "dailyTweetDf['ScaledDataAdjust'] = NormalizeData(dailyTweetDf,'SocialMediaValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reddit Comment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_52241/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "redditCommentsDf = DateTimeConvert(redditCommentsDf,'RunDate')\n",
    "redCommentDf = RemoveData(releaseDf, redditCommentsDf)\n",
    "redCommentDf['SocialMediaValue'] = redCommentDf['NumComments'] + redCommentDf['score']\n",
    "\n",
    "redCommentDf = redCommentDf[['TvShow','RunDate','SocialMediaValue']]\n",
    "iRedCommentDf = SumSocialMedia(redCommentDf, ['TvShow','RunDate'],1)\n",
    "iRedCommentDf['SocialMediaSource'] = 'RedditComments'\n",
    "\n",
    "iRedCommentDf = MergeDfs(iRedCommentDf, googDf1,['TvShow','RunDate'])\n",
    "iRedCommentDf = iRedCommentDf.fillna(0)\n",
    "iRedCommentDf = iRedCommentDf[iRedCommentDf['SocialMediaSource'] != 0]\n",
    "iRedCommentDf['GoogleAdjustedSocial'] = (iRedCommentDf['SocialMediaValue'] * iRedCommentDf['ScaledGoogleValue']) + iRedCommentDf['SocialMediaValue']\n",
    "\n",
    "iRedCommentDf['ScaledDataAdjustGoogle'] = NormalizeData(iRedCommentDf,'GoogleAdjustedSocial')\n",
    "iRedCommentDf['ScaledDataAdjust'] = NormalizeData(iRedCommentDf,'SocialMediaValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instagram Account Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_52241/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "igAccountDf = DateTimeConvert(igAccountDf,'RunDate')\n",
    "\n",
    "igAccountDf = DiffMaker(igAccountDf,'IgAccountCounts','RunDate')\n",
    "\n",
    "\n",
    "instaAccDf = RemoveData(releaseDf, igAccountDf)\n",
    "instaAccDf = NegativeDiffs(instaAccDf, 'diffs')\n",
    "instaAccDf['SocialMediaSource'] = 'InstagramAccount'\n",
    "instaAccDf['SocialMediaValue'] = instaAccDf['zeroedDiffs']\n",
    "\n",
    "instaAccDf = MergeDfs(instaAccDf, googDf1,['TvShow','RunDate'])\n",
    "instaAccDf = instaAccDf.fillna(0)\n",
    "instaAccDf = instaAccDf[instaAccDf['SocialMediaSource'] != 0]\n",
    "instaAccDf['GoogleAdjustedSocial'] = (instaAccDf['SocialMediaValue'] * instaAccDf['ScaledGoogleValue']) + instaAccDf['SocialMediaValue']\n",
    "\n",
    "instaAccDf['ScaledDataAdjustGoogle'] = NormalizeData(instaAccDf,'GoogleAdjustedSocial')\n",
    "instaAccDf['ScaledDataAdjust'] = NormalizeData(instaAccDf,'SocialMediaValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reddit Subscriber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/2b53j97121jg00pcthbt6kz80000gn/T/ipykernel_52241/2781502079.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bigDf = bigDf.append(newdf,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "redditSubsDf = DateTimeConvert(redditSubsDf,'RunDate')\n",
    "\n",
    "redditSubsDf = DiffMaker(redditSubsDf,'RedditSubs','RunDate')\n",
    "\n",
    "redSubDf = RemoveData(releaseDf, redditSubsDf)\n",
    "redSubDf = NegativeDiffs(redSubDf, 'diffs')\n",
    "redSubDf['SocialMediaSource'] = 'RedditSubscribers'\n",
    "redSubDf['SocialMediaValue'] = redSubDf['zeroedDiffs']\n",
    "\n",
    "redSubDf = MergeDfs(redSubDf, googDf1,['TvShow','RunDate'])\n",
    "redSubDf = redSubDf.fillna(0)\n",
    "redSubDf = redSubDf[redSubDf['SocialMediaSource'] != 0]\n",
    "redSubDf['GoogleAdjustedSocial'] = (redSubDf['SocialMediaValue'] * redSubDf['ScaledGoogleValue']) + redSubDf['SocialMediaValue']\n",
    "\n",
    "redSubDf['ScaledDataAdjustGoogle'] = NormalizeData(redSubDf,'GoogleAdjustedSocial')\n",
    "redSubDf['ScaledDataAdjust'] = NormalizeData(redSubDf,'SocialMediaValue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Release Date Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "releaseDateDf = DateTimeConvert(releaseDateDf,'EpisodeReleaseDate')\n",
    "iReleaseData = SumSocialMedia(releaseDateDf, ['TvShow','EpisodeReleaseDate'],0)\n",
    "iReleaseData['DailyReleaseCount'] = iReleaseData['EpisodeNumber']\n",
    "iReleaseData['RunDate'] = iReleaseData['EpisodeReleaseDate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time Value Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "instaAccDf = instaAccDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource','ScaledDataAdjust','GoogleAdjustedSocial','ScaledDataAdjustGoogle']]#,'diffs']]\n",
    "redSubDf = redSubDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource','ScaledDataAdjust','GoogleAdjustedSocial','ScaledDataAdjustGoogle']]#,'diffs']]\n",
    "dailyTweetDf = dailyTweetDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource','ScaledDataAdjust','GoogleAdjustedSocial','ScaledDataAdjustGoogle']]\n",
    "instaHashDf = instaHashDf[['TvShow','RunDate','SocialMediaValue','SocialMediaSource','ScaledDataAdjust','GoogleAdjustedSocial','ScaledDataAdjustGoogle']]#,'diffs']]\n",
    "# reddit comment data is combined elsewhere\n",
    "iReleaseData = iReleaseData[['TvShow','RunDate','DailyReleaseCount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "uberDf2 = pd.concat([instaAccDf,redSubDf,dailyTweetDf,instaHashDf,iRedCommentDf])#,googDf1])\n",
    "\n",
    "uberDf3 = MergeDfs(uberDf2, releaseDf,'TvShow')\n",
    "uberDf3\n",
    "\n",
    "uberDf3 = MergeDfs(uberDf3, iReleaseData,['TvShow','RunDate'])\n",
    "uberDf3 = uberDf3[uberDf3['Ignore'] == 1]\n",
    "uberDf3 = uberDf3.fillna(0)\n",
    "uberDf3['PostReleaseDay'] = (uberDf3['RunDate'] - uberDf3['Release Date']).astype(str).str.replace(' days','').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output - individuals & uber dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "uberDf3 = uberDf3.sort_values(['TvShow','RunDate','SocialMediaSource'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "uberdf4= uberDf3[uberDf3['PostReleaseDay'] <= 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uberdf5 = MergeDfs(uberdf4, googDf1,['TvShow','RunDate'])\n",
    "uberdf5= uberdf4[uberdf4['PostReleaseDay'] <= 90].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filepath2 = r'/Users/cartersocha/Downloads/uberDataset3.csv'\n",
    "\n",
    "uberdf5.to_csv(filepath2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
